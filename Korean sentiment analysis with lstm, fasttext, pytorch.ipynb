{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Develop log\n",
    "\n",
    "24.04.19\n",
    "- 학습이 안 되던 문제를 해결. label의 데이터 값이 0, 1로 정수형인데, 이 녀석을 부동소수형으로 변형하여 loss를 계산하던 것이 문제인듯함. label의 값을 LongTensor로 변환하여 loss값을 구하였더니 정상적으로 학습이 됨을 확인함. \n",
    "- 다른 문제로 모델의 성능이 상당히 떨어짐을 확인함. validation의 정확도를 기준으로 5epoch에서 정확도가 최대였음. 해당 epoch에서의 train의 정확도는 72% 가량 나옴. 좀 더 정확도를 올릴 수 있는 방법을 찾아보는 것이 좋을듯 함.\n",
    "- 위와 같이 정확도가 크게 올라가지 못하는 이유로 다음과 같이 추정.\n",
    "fasttext모델을 학습에 사용하는 코퍼스가 아닌 다른 코퍼스를 사용하여 학습함. 여기서부터 오는 약간의 간극과 더불어 학습에 사용된 코퍼스가 맞춤법이 부정확한 댓글의 특성에 더해져 더욱 큰 성능의 감소를 가져왔다고 추정됨.\n",
    "\n",
    "24.04.23\n",
    "- float 이어도 정상적으로 학습이 됨...? 이전 버전의 내용을 확인해봐야 할 필요가 있어보임\n",
    "- lstm model에서 hidden state가 제대로 된 내용을 리턴하지 않음. 텐서에 0값만 들어있음. -> 이 부분이 문제가 될 수 있다고 생각됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. fasttext model 변경 : Not worked\n",
    "2. dataset label 반환 변경 : Not worked\n",
    "3. lstm model hidden state 반환 유무 변경 : Not worked\n",
    "4. optimizer.step() 추가 : Worked but why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hgtk\n",
    "from tqdm import tqdm\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Dataset, TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(forms:list):\n",
    "    word = ''\n",
    "    for form in forms:\n",
    "        try:\n",
    "            if hgtk.checker.is_hangul(form):\n",
    "                for s in form:\n",
    "                    a, b, c = hgtk.letter.decompose(s)\n",
    "                    if not a:\n",
    "                        a = '-'\n",
    "                    if not b:\n",
    "                        b = '-'\n",
    "                    if not c:\n",
    "                        c = '-'\n",
    "                    word = word + a + b + c\n",
    "        except TypeError as e:\n",
    "            print(form)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = fasttext.load_model(\"fasttext_with_NIKL_MP_CSV.bin\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_dir, num_word, transform = None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_dir).sample(frac=1)[:5000]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.num_word = num_word\n",
    "        self.labels = torch.from_numpy(self.df['label'].values).type(torch.float32)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        sent = self.df['morphologized_sent'].iloc[i]\n",
    "        padded_vec = torch.zeros((self.num_word, fast_model.get_dimension()), dtype = torch.float32)\n",
    "        \n",
    "        sent2vec = [] \n",
    "        for w in sent:\n",
    "            if w.rstrip():\n",
    "                sent2vec.append(fast_model.get_word_vector(decompose(w)))\n",
    "        sent2vec = np.array(sent2vec)\n",
    "        len_sent = len(sent2vec)\n",
    "        if len_sent > self.num_word:\n",
    "            len_sent = self.num_word\n",
    "        padded_vec[(self.num_word - len_sent):] = torch.from_numpy(sent2vec[:len_sent])\n",
    "         \n",
    "        return (padded_vec, self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./morphologized_ratings.csv', num_word=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean       18.139200\n",
       "std        15.326461\n",
       "min         1.000000\n",
       "25%         8.000000\n",
       "50%        14.000000\n",
       "75%        22.000000\n",
       "max       101.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len = [len(s.split()) for s in dataset.df['morphologized_sent']]\n",
    "pd.Series(sent_len).hist()\n",
    "plt.show()\n",
    "pd.Series(sent_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dic = defaultdict(int)\n",
    "\n",
    "for n in sent_len:\n",
    "    dic[n] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 1\n"
     ]
    }
   ],
   "source": [
    "total_cnt = 0\n",
    "for length, cnt in dic.items():\n",
    "    total_cnt += cnt\n",
    "    \n",
    "    if total_cnt // len(sent_len) * 100 > 90:\n",
    "        print(length, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "valid_size = len(dataset) - train_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5736, -2.5102,  0.4100,  ..., -2.1188,  2.7128, -2.1250],\n",
      "         [ 0.5736, -2.5102,  0.4100,  ..., -2.1188,  2.7128, -2.1250],\n",
      "         [ 0.6993, -0.0494,  1.0716,  ...,  0.7159,  2.3881,  3.3445],\n",
      "         ...,\n",
      "         [ 0.3715, -0.0746, -0.4935,  ...,  0.7481,  0.4270,  0.7597],\n",
      "         [ 0.2678, -1.2395,  2.1219,  ...,  2.3317,  4.0463, -0.2475],\n",
      "         [-1.9040,  2.4636,  0.6963,  ..., -0.6284,  2.5350, -0.9129]],\n",
      "\n",
      "        [[ 3.1410, -3.5550, -1.4895,  ...,  1.4553,  0.6382, -1.5765],\n",
      "         [-2.9753,  0.4030,  0.3323,  ..., -0.4623, -1.6382,  0.1496],\n",
      "         [ 3.5028, -0.2681, -1.1440,  ...,  0.3329,  0.6166,  0.9899],\n",
      "         ...,\n",
      "         [ 3.1898,  0.4495,  0.3376,  ..., -0.7893,  3.3636, -1.4090],\n",
      "         [-1.0350, -2.5387, -0.6889,  ...,  2.2851, -1.4118,  1.8538],\n",
      "         [ 3.5028, -0.2681, -1.1440,  ...,  0.3329,  0.6166,  0.9899]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.6764, -1.3522, -1.7868,  ..., -0.3383,  2.6748,  1.4060],\n",
      "         [ 3.5028, -0.2681, -1.1440,  ...,  0.3329,  0.6166,  0.9899],\n",
      "         [-0.0827,  1.6279,  2.2731,  ..., -0.5362, -2.6669, -1.5724]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8484,  1.2487, -1.5080,  ..., -2.4276,  0.1670, -1.6382],\n",
      "         [ 0.1597, -4.6352, -7.3839,  ...,  0.1160,  2.5023,  0.3727],\n",
      "         [ 3.1712, -0.1165, -1.1945,  ...,  0.7968,  1.4937, -0.0166],\n",
      "         ...,\n",
      "         [ 0.0979,  0.0196, -1.3056,  ...,  1.4171,  1.3301,  1.8128],\n",
      "         [-0.7116, -1.3227,  1.4291,  ...,  1.4821,  0.7787, -0.4353],\n",
      "         [-0.5315, -0.1621, -1.2691,  ..., -0.2311,  0.7494, -1.0004]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 1.6354,  0.7931,  0.3468,  ...,  0.7538, -0.3091, -0.9775],\n",
      "         [-1.6058,  1.0482,  1.8018,  ..., -0.9936,  0.4669,  0.7156],\n",
      "         [-1.8232,  1.0065,  2.4744,  ...,  0.1948, -2.9623,  0.6539]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 4.0056, -0.9015,  0.8713,  ...,  3.2828,  0.5830, -1.8416],\n",
      "         [ 0.1695,  0.7167, -1.8877,  ...,  0.9268,  0.4040, -0.5602],\n",
      "         [ 0.0577, -0.4284, -0.4100,  ...,  0.0617,  0.5871, -1.0459]]])\n",
      "tensor([0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.])\n",
      "torch.Size([32, 32, 100])\n"
     ]
    }
   ],
   "source": [
    "train_sent, train_label = next(iter(train_dataloader))\n",
    "print(train_sent)\n",
    "print(train_label)\n",
    "print(train_sent.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_dim, num_word):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers,batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        re_drop_out = drop_out.reshape([-1, self.hidden_size])\n",
    "            \n",
    "        linear_out = self.linear(re_drop_out)\n",
    "        \n",
    "        sig_out = self.sig(linear_out).reshape([batch_size, -1])[:, -1]\n",
    "        \n",
    "        return sig_out\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), dtype=torch.float32).to(device)\n",
    "        c0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), dtype=torch.float32).to(device)\n",
    "        \n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "input_size = 100\n",
    "hidden_size = 128\n",
    "output_dim = 1\n",
    "\n",
    "num_word = 32\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = SentimentLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_dim=output_dim, num_word=num_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "clip = 5\n",
    "epochs = 5\n",
    "\n",
    "loss_func = nn.BCELoss()#.to(device)\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = lr)\n",
    "\n",
    "def acc(pred, label):\n",
    "    correct = torch.eq(pred.round(), label).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:14<00:00,  8.87it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.6579522981643676 val_loss : 0.6524994056671858\n",
      "train_accuracy : 60.375 val_accuracy : 60.8\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:14<00:00,  8.91it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "train_loss : 0.5904372863769531 val_loss : 0.6175963263958693\n",
      "train_accuracy : 68.525 val_accuracy : 65.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:13<00:00,  8.97it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "train_loss : 0.5254666419029236 val_loss : 0.6048606112599373\n",
      "train_accuracy : 74.2 val_accuracy : 68.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:13<00:00,  8.95it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "train_loss : 0.4788959572315216 val_loss : 0.6046268371865153\n",
      "train_accuracy : 77.775 val_accuracy : 70.3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:14<00:00,  8.92it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "train_loss : 0.3855954954624176 val_loss : 0.6109053655527532\n",
      "train_accuracy : 82.875 val_accuracy : 68.89999999999999\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_tr_acc, epoch_tr_loss = [], []\n",
    "epoch_vl_acc, epoch_vl_loss = [],[]\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    lstm_model.train()\n",
    "    #h = lstm_model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #h = tuple([each.data for each in h])\n",
    "        \n",
    "        pred = lstm_model(inputs)\n",
    "        \n",
    "        loss = loss_func(pred, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        train_acc += accuracy\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(lstm_model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    \n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    lstm_model.eval()\n",
    "    #val_h = lstm_model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(valid_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #val_h = tuple([each.data for each in val_h])\n",
    "        pred = lstm_model(inputs)\n",
    "\n",
    "        val_loss = loss_func(pred, labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        val_acc += accuracy\n",
    "    \n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_val_acc = val_acc/len(valid_dataloader.dataset)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
