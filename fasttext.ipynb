{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hgtk\n",
    "from tqdm import tqdm\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(forms:list):\n",
    "    word = ''\n",
    "    for form in forms:\n",
    "        try:\n",
    "            if hgtk.checker.is_hangul(form):\n",
    "                for s in form:\n",
    "                    a, b, c = hgtk.letter.decompose(s)\n",
    "                    if not a:\n",
    "                        a = '-'\n",
    "                    if not b:\n",
    "                        b = '-'\n",
    "                    if not c:\n",
    "                        c = '-'\n",
    "                    word = word + a + b + c\n",
    "        except TypeError as e:\n",
    "            print(form)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = fasttext.load_model(\"fasttext_jn.bin\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(word_sequence):\n",
    "    return [(compose(word), similarity) for (similarity, word) in word_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Dataset, TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_dir, num_word, transform = None, target_transform=None):\n",
    "        self.df = pd.read_csv(csv_dir).sample(frac=1)[:5120]  #\n",
    "        self.transform = transform                 #\n",
    "        self.target_transform = target_transform     #\n",
    "        self.num_word = num_word          #\n",
    "        #self.labels = torch.form_numpy( ... )...\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        sent = self.df['morphologized_sent'].iloc[i]\n",
    "        label = self.df['label'].iloc[i]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        padded_vec = torch.zeros((self.num_word, fast_model.get_dimension()), dtype = torch.float32)\n",
    "        \n",
    "        sent2vec = [] \n",
    "        for w in sent:\n",
    "            if w.rstrip():\n",
    "                sent2vec.append(fast_model.get_word_vector(decompose(w)))\n",
    "        sent2vec = np.array(sent2vec)\n",
    "        len_sent = len(sent2vec)\n",
    "        if len_sent > self.num_word:\n",
    "            len_sent = self.num_word\n",
    "        padded_vec[(self.num_word - len_sent):] = torch.from_numpy(sent2vec[:len_sent])\n",
    "        \n",
    "        return (padded_vec, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./morphologized_ratings.csv', num_word=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "valid_size = len(dataset) - train_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 100])\n"
     ]
    }
   ],
   "source": [
    "train_sent, train_label = next(iter(train_dataloader))\n",
    "print(train_sent.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_dim):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers,batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        re_drop_out = drop_out.reshape([-1, self.hidden_size])\n",
    "        \n",
    "        linear_out = self.linear(re_drop_out)\n",
    "        \n",
    "        sig_out = self.sig(linear_out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, (hn, cn)\n",
    "        \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), dtype=torch.float32).to(device)\n",
    "        c0 = torch.zeros((self.num_layers, batch_size, self.hidden_size), dtype = torch.float32).to(device)\n",
    "        hidden = (h0, c0)\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "input_size = 100\n",
    "hidden_size = 128\n",
    "output_dim = 1\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = SentimentLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "clip = 5\n",
    "epochs = 5\n",
    "\n",
    "loss_func = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = lr)\n",
    "\n",
    "def acc(pred, label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(dataloader, model):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        pred, h = model(inputs, hidden)\n",
    "        \n",
    "        loss = loss_func(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        train_acc += accuracy\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n",
    "        \n",
    "    return epoch_train_loss, epoch_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_valid(dataloader, model):\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        hidden = tuple([each.data for each in hidden])\n",
    "        \n",
    "        pred, h = model(inputs, hidden)\n",
    "\n",
    "        val_loss = loss_func(pred.squeeze(), labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        val_acc += accuracy\n",
    "\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_val_acc = val_acc/len(valid_dataloader.dataset)\n",
    "        \n",
    "    return epoch_val_acc, epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [03:40<00:00,  1.72s/it] \n",
      "100%|██████████| 32/32 [00:03<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.689701902680099 val_loss : 0.5517578125\n",
      "train_accuracy : 53.22265625 val_accuracy : 68.67739334702492\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  9.13it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "train_loss : 0.6637472449801862 val_loss : 0.6220703125\n",
      "train_accuracy : 60.009765625 val_accuracy : 65.1546711102128\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  9.11it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "train_loss : 0.6347051730845124 val_loss : 0.65234375\n",
      "train_accuracy : 63.57421875 val_accuracy : 63.573151640594006\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  9.09it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "train_loss : 0.5989367868751287 val_loss : 0.6533203125\n",
      "train_accuracy : 67.9931640625 val_accuracy : 61.98324151337147\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:14<00:00,  9.11it/s]\n",
      "100%|██████████| 32/32 [00:02<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "train_loss : 0.57958365813829 val_loss : 0.66015625\n",
      "train_accuracy : 69.62890625 val_accuracy : 61.19313444942236\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "epoch_tr_acc, epoch_tr_loss = [], []\n",
    "epoch_vl_acc, epoch_vl_loss = [],[]\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss, epoch_train_acc = model_train(train_dataloader, lstm_model)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    \n",
    "    epoch_val_loss, epoch_val_acc = model_valid(valid_dataloader, lstm_model)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    \n",
    "    \n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "#plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "#plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model, './lstm_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[ 0.0146,  0.0404, -0.0509,  ..., -0.0385,  0.0166, -0.0370],\n",
    "        [-0.0597,  0.0739, -0.0145,  ...,  0.0483,  0.0412, -0.0676],\n",
    "        [-0.0344,  0.0557, -0.0689,  ..., -0.0809, -0.0663, -0.0484],\n",
    "        ...,\n",
    "        [ 0.0731,  0.0145,  0.0480,  ...,  0.0547,  0.0167,  0.0485],\n",
    "        [-0.0729,  0.0058,  0.0433,  ...,  0.0633, -0.0016,  0.0611],\n",
    "        [ 0.0038,  0.0102,  0.0623,  ..., -0.0873, -0.0795, -0.0269]],\n",
    "       device='cuda:0')\n",
    "tensor([[-0.0645, -0.0076,  0.0543,  ..., -0.0806, -0.0366,  0.0484],\n",
    "        [-0.0302,  0.0088, -0.0471,  ..., -0.0544, -0.0489, -0.0127],\n",
    "        [ 0.0427, -0.0663,  0.0533,  ...,  0.0839, -0.0501,  0.0093],\n",
    "        ...,\n",
    "        [ 0.0835, -0.0768, -0.0571,  ..., -0.0208,  0.0873,  0.0026],\n",
    "        [-0.0453,  0.0513,  0.0046,  ...,  0.0104, -0.0859,  0.0382],\n",
    "        [-0.0277,  0.0273, -0.0566,  ..., -0.0058, -0.0035,  0.0348]],\n",
    "       device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[ 0.0146,  0.0404, -0.0509,  ..., -0.0385,  0.0166, -0.0370],\n",
    "        [-0.0597,  0.0739, -0.0145,  ...,  0.0483,  0.0412, -0.0676],\n",
    "        [-0.0344,  0.0557, -0.0689,  ..., -0.0809, -0.0663, -0.0484],\n",
    "        ...,\n",
    "        [ 0.0731,  0.0145,  0.0480,  ...,  0.0547,  0.0167,  0.0485],\n",
    "        [-0.0729,  0.0058,  0.0433,  ...,  0.0633, -0.0016,  0.0611],\n",
    "        [ 0.0038,  0.0102,  0.0623,  ..., -0.0873, -0.0795, -0.0269]],\n",
    "       device='cuda:0')\n",
    "tensor([[-0.0645, -0.0076,  0.0543,  ..., -0.0806, -0.0366,  0.0484],\n",
    "        [-0.0302,  0.0088, -0.0471,  ..., -0.0544, -0.0489, -0.0127],\n",
    "        [ 0.0427, -0.0663,  0.0533,  ...,  0.0839, -0.0501,  0.0093],\n",
    "        ...,\n",
    "        [ 0.0835, -0.0768, -0.0571,  ..., -0.0208,  0.0873,  0.0026],\n",
    "        [-0.0453,  0.0513,  0.0046,  ...,  0.0104, -0.0859,  0.0382],\n",
    "        [-0.0277,  0.0273, -0.0566,  ..., -0.0058, -0.0035,  0.0348]],\n",
    "       device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
