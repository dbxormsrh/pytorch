{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training fasttext model\n",
    "\n",
    "Using corpus : https://81675795.ucloudcdnglobal.com/122/NIKL_MP_v1.1.pdf\n",
    "https://kli.korean.go.kr/corpus/main/requestMain.do -> 형태 분석 말뭉치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import hgtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(form):\n",
    "    word = ''\n",
    "    try:\n",
    "        for s in form:\n",
    "            if s == ' ':\n",
    "                word += ''\n",
    "            elif hgtk.checker.is_hangul(s):\n",
    "                a, b, c = hgtk.letter.decompose(s)\n",
    "                if not a:\n",
    "                    a = '-'\n",
    "                if not b:\n",
    "                    b = '-'\n",
    "                if not c:\n",
    "                    c = '-'\n",
    "                word = word + a + b + c\n",
    "    except e:\n",
    "        print(e)\n",
    "        print(f'except: {form}')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = '../NIKL_MP_CSV/NXMP1902008040_{}.csv'    #문장이 sentence로, 문장을 형태소로 분석한 내용이 form으로 들어가 있음\n",
    "with open('decomposed_sent.txt', 'w') as f:\n",
    "    for i in range(5):\n",
    "        df = pd.read_csv(df_name.format(i + 1), skipinitialspace=True, usecols=('sentence_id', 'form'))\n",
    "        sent_form={}\n",
    "        pre_sent = ''\n",
    "        \n",
    "        for value in tqdm(df.values):\n",
    "            sent, form = value[0], value[1]\n",
    "            sent = re.sub('ㄱ-ㅎ')\n",
    "            if pre_sent != sent:\n",
    "                sent_form[sent] = []\n",
    "                pre_sent = sent\n",
    "            sent_form[sent].append(form)\n",
    "            \n",
    "        for form in tqdm(sent_form.values()):\n",
    "            f.write(' '.join(decompose(form)) + '\\n')      #decompose('안녕하세요') == 'ㅇㅏㄴㄴㅕㅇㅎㅏㅅㅔ-ㅇㅛ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.train_unsupervised('decomposed_sent.txt', dim = 100, epoch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model.save_model('fasttext_with_NIKL_MP_CSV.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing training data with Khaiii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from khaiii import KhaiiiApi\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "khaiii_api = KhaiiiApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt', filename = 'ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('./ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['document'] = df['document'].str.replace('[^ㄱ-ㅎ가-힣]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(index=df[df['document'].str.rstrip() == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('morphs_label.txt', 'w') as out:\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        sent = row['document']\n",
    "        sent = ' '.join(sent.split())\n",
    "        label = row['label']\n",
    "        morphs = ''\n",
    "        try:\n",
    "            for word in khaiii_api.analyze(sent):\n",
    "                for m in word.morphs:\n",
    "                    morphs += m.lex + ' '\n",
    "        except:\n",
    "            print(idx, row)\n",
    "            break\n",
    "        out.write(morphs + '\\t' + str(label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./morphs_label.txt', 'r')\n",
    "ori_data = []\n",
    "for line in file:\n",
    "    morphs, label = line.split('\\t')\n",
    "    ori_data.append((morphs, int(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label '1' : 96588 / label '0' : 96901\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "f = 0\n",
    "for (_, y) in ori_data:\n",
    "    if y:\n",
    "        t += 1\n",
    "    else:\n",
    "        f += 1\n",
    "\n",
    "print(f'label \\'1\\' : {t} / label \\'0\\' : {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    193489.000000\n",
       "mean         18.254717\n",
       "std          15.475947\n",
       "min           1.000000\n",
       "25%           8.000000\n",
       "50%          14.000000\n",
       "75%          22.000000\n",
       "max         109.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len = [len(s[0].split()) for s in ori_data]\n",
    "pd.Series(sent_len).hist()\n",
    "plt.show()\n",
    "pd.Series(sent_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "for n in sent_len:\n",
    "    if n in dic:\n",
    "        dic[n] += 1\n",
    "    else:\n",
    "        dic[n] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 90% / key : 39, total_count : 174443\n",
      "key > = 64 :  97.01998563225817\n"
     ]
    }
   ],
   "source": [
    "total_cnt = 0\n",
    "keys = sorted(dic.keys())\n",
    "f = True\n",
    "for key in keys:\n",
    "    cnt = dic[key]\n",
    "    total_cnt += cnt\n",
    "    if key >= 64:\n",
    "        print('key > = 64 : ', total_cnt / len(ori_data) * 100)\n",
    "        break\n",
    "        \n",
    "    if (total_cnt / len(ori_data)) * 100 > 90 and f:\n",
    "        print(f'over 90% / key : {key}, total_count : {total_cnt}')\n",
    "        f = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = fasttext.load_model(\"fasttext_with_NIKL_MP_CSV.bin\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, num_word, transform = None, target_transform=None):\n",
    "        file = open(data_dir, 'r')\n",
    "        self.ori_data = []\n",
    "        for line in file:\n",
    "            morphs, label = line.split('\\t')\n",
    "            self.ori_data.append((morphs, int(label)))\n",
    "        shuffle(self.ori_data)\n",
    "        self.data = self.ori_data\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.num_word = num_word\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        sent = self.data[i][0]\n",
    "        \n",
    "        len_sent = len(sent.split())\n",
    "        if len_sent > self.num_word:\n",
    "            len_sent = self.num_word\n",
    "            \n",
    "        morphs = sent.split()\n",
    "        sent2vec = np.zeros((self.num_word, fast_model.get_dimension()), dtype = np.float32)\n",
    "        \n",
    "        for i in range(len_sent):\n",
    "            s = morphs[i]\n",
    "            word_vec = fast_model.get_word_vector(decompose(s)).astype(np.float32)\n",
    "            sent2vec[-(i + 1)] = word_vec\n",
    "            \n",
    "        padded_vec = torch.from_numpy(sent2vec)\n",
    "\n",
    "        label = torch.tensor(self.data[i][1], dtype = torch.float32)\n",
    "        return (padded_vec, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./morphs_label.txt', num_word = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.8)\n",
    "valid_size = len(dataset) - train_size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4257, -1.7780,  0.6667,  ...,  0.3363, -0.4424, -0.7800],\n",
      "         [-0.2317,  0.6963, -2.2494,  ...,  0.0929, -0.5272, -0.5534],\n",
      "         [ 0.5369,  0.6295,  0.2788,  ..., -1.1247,  2.1629, -0.6539],\n",
      "         ...,\n",
      "         [-0.2317,  0.6963, -2.2494,  ...,  0.0929, -0.5272, -0.5534],\n",
      "         [-0.3828, -0.0698, -1.7251,  ..., -1.0197, -0.5473, -1.1731],\n",
      "         [ 0.5911, -0.6682,  0.2173,  ...,  0.6923, -1.4788,  0.6476]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.3769,  0.6465,  0.1578,  ...,  0.5257,  0.1524, -0.2173],\n",
      "         [-0.3828, -0.0698, -1.7251,  ..., -1.0197, -0.5473, -1.1731],\n",
      "         [ 3.5028, -0.2681, -1.1440,  ...,  0.3329,  0.6166,  0.9899]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.4346,  0.1523, -1.2007,  ...,  0.8891,  1.2796,  0.1506],\n",
      "         [-0.9219,  0.5318, -2.3514,  ...,  0.1279,  0.3868,  3.0293],\n",
      "         [ 1.1028, -0.2301, -0.0819,  ...,  0.0461,  0.7930, -0.1876]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.9193, -0.0473, -0.2337,  ..., -2.4366,  2.7791, -0.1332],\n",
      "         [-1.3906,  1.7199,  2.6207,  ...,  0.3929,  0.1093,  0.5020],\n",
      "         [ 3.5028, -0.2681, -1.1440,  ...,  0.3329,  0.6166,  0.9899]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.6764, -1.3522, -1.7868,  ..., -0.3383,  2.6748,  1.4060],\n",
      "         [ 0.8791,  1.1327,  0.9605,  ..., -0.3806,  0.5072, -0.3509],\n",
      "         [ 3.7888,  0.1661, -0.5596,  ..., -0.8758,  1.6857,  3.2865]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.8153, -0.3464, -0.7577,  ...,  0.7902,  0.1706, -1.0433],\n",
      "         [-0.0287,  0.1926,  0.3997,  ..., -1.0222,  0.3852,  0.5442],\n",
      "         [ 0.8734, -1.2281, -1.1662,  ...,  0.9690, -0.4857,  0.6774]]])\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.])\n",
      "torch.Size([32, 64, 100])\n"
     ]
    }
   ],
   "source": [
    "train_sent, train_label = next(iter(train_dataloader))\n",
    "print(train_sent)\n",
    "print(train_label)\n",
    "print(train_sent.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, d in tqdm(valid_dataloader):\n",
    "    if d.sum() < len(d):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_dim):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers,batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        re_drop_out = drop_out.reshape([-1, self.hidden_size])\n",
    "            \n",
    "        linear_out = self.linear(re_drop_out)\n",
    "        \n",
    "        sig_out = self.sig(linear_out).reshape([batch_size, -1])[:, -1]\n",
    "        \n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "input_size = 100\n",
    "hidden_size = 128\n",
    "output_dim = 1\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = SentimentLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "clip = 5\n",
    "epochs = 5\n",
    "\n",
    "loss_func = nn.BCELoss()#.to(device)\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = lr)\n",
    "\n",
    "def acc(pred, label):\n",
    "    correct = torch.eq(pred.round(), label).sum().item()\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_tr_acc, epoch_tr_loss = [], []\n",
    "epoch_vl_acc, epoch_vl_loss = [],[]\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    lstm_model.train()\n",
    "    #h = lstm_model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #h = tuple([each.data for each in h])\n",
    "        \n",
    "        pred = lstm_model(inputs)\n",
    "        \n",
    "        loss = loss_func(pred, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        train_acc += accuracy\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(lstm_model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    \n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    lstm_model.eval()\n",
    "    #val_h = lstm_model.init_hidden(batch_size, device)\n",
    "\n",
    "    for inputs, labels in tqdm(valid_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #val_h = tuple([each.data for each in val_h])\n",
    "        pred = lstm_model(inputs)\n",
    "\n",
    "        val_loss = loss_func(pred, labels.float())\n",
    "        val_losses.append(val_loss.item())\n",
    "        accuracy = acc(pred, labels)\n",
    "\n",
    "        val_acc += accuracy\n",
    "    \n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_val_acc = val_acc/len(valid_dataloader.dataset)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model, f='./k_sentiment_Fasttext_LSTM.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x = torch.load('./k_sentiment_Fasttext_LSTM.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from khaiii import KhaiiiApi\n",
    "import fasttext\n",
    "import hgtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(form):\n",
    "    word = ''\n",
    "    try:\n",
    "        for s in form:\n",
    "            if s == ' ':\n",
    "                word += ''\n",
    "            elif hgtk.checker.is_hangul(s):\n",
    "                a, b, c = hgtk.letter.decompose(s)\n",
    "                if not a:\n",
    "                    a = '-'\n",
    "                if not b:\n",
    "                    b = '-'\n",
    "                if not c:\n",
    "                    c = '-'\n",
    "                word = word + a + b + c\n",
    "    except e:\n",
    "        print(e)\n",
    "        print(f'except: {form}')\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_dim):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.outbput_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers,batch_first = True)\n",
    "        \n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        re_drop_out = drop_out.reshape([-1, self.hidden_size])\n",
    "            \n",
    "        linear_out = self.linear(re_drop_out)\n",
    "        \n",
    "        sig_out = self.sig(linear_out).reshape([batch_size, -1])[:, -1]\n",
    "        \n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_model = torch.load('../k_sentiment_Fasttext_LSTM.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "khaiii = KhaiiiApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_model = fasttext.load_model('../fasttext_with_NIKL_MP_CSV.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7167325019836426, 'ㅎㅏㄴㄱㅜㄱHP'),\n",
       " (0.7131243944168091, 'ㅎㅏㄴㄱㅜㄱGM'),\n",
       " (0.708922803401947, 'ㄴㅏㄴㄱㅜㄱ'),\n",
       " (0.676729142665863, 'ㅅㅣㄴㅎㅡㅇㄱㅜㄱ'),\n",
       " (0.6687567234039307, 'ㅎㅏㄴㄱㅜㄱㄱㅜㄱㅈㅔ-ㅎㅕㅂㄹㅕㄱㄷㅏㄴ'),\n",
       " (0.6656281352043152, 'ㅈㅜㅇㄱㅜㄱㅅㅣㄱ'),\n",
       " (0.6548346877098083, 'ㅁㅏㄴㄱㅜㄱ'),\n",
       " (0.6545369625091553, 'ㄸㅓㄱㄱㅜㄱ'),\n",
       " (0.6516401171684265, 'ㅎㅏㄴㄱㅜㄱㅎㅐㅇ'),\n",
       " (0.6499113440513611, 'ㅎㅏㄴㄱㅜㄱㅁㅏㄹ')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_model.get_analogies(decompose('한국'), decompose('미국'), decompose('중국'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sent(sent, fast_model, lstm_model, khaiii, num_word):\n",
    "    morphs = []\n",
    "    try:\n",
    "        for word in khaiii.analyze(sent):\n",
    "            for m in word.morphs:\n",
    "                morphs.append(m.lex)\n",
    "    except:\n",
    "        print('Can\\'t analyze sentence')\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    if len(morphs) > num_word:\n",
    "        morphs = morphs[:num_word]\n",
    "        \n",
    "    sent_vec = np.zeros((num_word, fast_model.get_dimension()), dtype=np.float32)\n",
    "    \n",
    "    for i, m in zip(range(num_word), morphs):\n",
    "        word_vec = fast_model.get_word_vector(decompose(m)).astype(np.float32)\n",
    "        sent_vec[-(i + 1)] = word_vec\n",
    "    \n",
    "    sent_tensor = torch.from_numpy(sent_vec)\n",
    "    sent_tensor = sent_tensor.reshape([1, num_word, fast_model.get_dimension()])\n",
    "\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        sent_tensor = sent_tensor.to(device)\n",
    "    \n",
    "    lstm_model.eval()\n",
    "    \n",
    "    pred = lstm_model(sent_tensor)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0310], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "부정\n"
     ]
    }
   ],
   "source": [
    "pred = analyze_sent('', fast_model, lstm_model, khaiii, 64)\n",
    "print(pred)\n",
    "      \n",
    "if pred.item() > 0.5:\n",
    "    print('긍정')\n",
    "else :\n",
    "    print('부정')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
